{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network Regressor\n",
    "======================\n",
    "# Using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow\timport keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\fliko\\git_practice\\regression-challenge\\regression-challenge\\regression-challenge-starter\\admissions_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Serial No.   GRE Score  TOEFL Score  University Rating         SOP  \\\n",
      "count  500.000000  500.000000   500.000000         500.000000  500.000000   \n",
      "mean   250.500000  316.472000   107.192000           3.114000    3.374000   \n",
      "std    144.481833   11.295148     6.081868           1.143512    0.991004   \n",
      "min      1.000000  290.000000    92.000000           1.000000    1.000000   \n",
      "25%    125.750000  308.000000   103.000000           2.000000    2.500000   \n",
      "50%    250.500000  317.000000   107.000000           3.000000    3.500000   \n",
      "75%    375.250000  325.000000   112.000000           4.000000    4.000000   \n",
      "max    500.000000  340.000000   120.000000           5.000000    5.000000   \n",
      "\n",
      "            LOR         CGPA    Research  Chance of Admit   \n",
      "count  500.00000  500.000000  500.000000         500.00000  \n",
      "mean     3.48400    8.576440    0.560000           0.72174  \n",
      "std      0.92545    0.604813    0.496884           0.14114  \n",
      "min      1.00000    6.800000    0.000000           0.34000  \n",
      "25%      3.00000    8.127500    0.000000           0.63000  \n",
      "50%      3.50000    8.560000    1.000000           0.72000  \n",
      "75%      4.00000    9.040000    1.000000           0.82000  \n",
      "max      5.00000    9.920000    1.000000           0.97000  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 7)\n"
     ]
    }
   ],
   "source": [
    "#Dividing the dataset into labels and features\n",
    "labels = df.iloc[:,-1]\n",
    "features = df.iloc[:,:-1]\n",
    "features = features.drop(columns = ['Serial No.'])\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset into training and test data\n",
    "features_train,features_test,labels_train,labels_test = train_test_split(features,labels,test_size = 0.2,\n",
    "                                                                        random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "#Scaling the data because of great differences in magnitude\n",
    "scaler = StandardScaler()\n",
    "features_train = pd.DataFrame(scaler.fit_transform(features_train))\n",
    "features_test = pd.DataFrame(scaler.transform(features_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 500, 16)           128       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 128\n",
      "Trainable params: 128\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Starting the model\n",
    "def model():\n",
    "    model = Sequential()\n",
    "    model.add(keras.Input(shape = (500,7)))\n",
    "    model.add(layers.Dense(16,activation = 'relu'))\n",
    "    \n",
    "    model.compile(loss = 'mean_squared_error',\n",
    "                 optimizer = 'adam',\n",
    "                 metrics = ['MAE'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(model().summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
